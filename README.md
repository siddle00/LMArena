# LMArena
Experiments with Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) on LM-Arena datasets (50k &amp; 140k). Includes dataset prep, EDA, training scripts, evaluation with MT-Bench/LLM-J, and LoRA adapters for Mistral-7B.
