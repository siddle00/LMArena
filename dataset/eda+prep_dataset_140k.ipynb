{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f24edf-4630-4974-ad99-309763b75c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c6a2f40f90466d95c0df016e3d0663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14440be52b8451f9201f7293095a593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00007.parquet:   0%|          | 0.00/232M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c82fe400b44dc2965626d325a34889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00007.parquet:   0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8196aff0f5a46ed88e055bcbed2ee80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00002-of-00007.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f056f552c6ff48c7852c8c3354087385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00003-of-00007.parquet:   0%|          | 0.00/230M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed2a9b8ab634dbd9b5c96085a8f35d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00004-of-00007.parquet:   0%|          | 0.00/229M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9c9be91dce48a58dd6575de3e0544a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00005-of-00007.parquet:   0%|          | 0.00/232M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46fa85ff4f44fc8b8acf467987dedaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00006-of-00007.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafb6acb54b14fc2b63059446c70c51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/135634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset_1 = load_dataset(\"lmarena-ai/arena-human-preference-140k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33524857-fcdc-4296-8096-41369776f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.DataFrame(dataset_1['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3993e0dc-988a-48e8-9ac6-643604ae815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, os\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "\n",
    "def _as_text(x):\n",
    "    \"\"\"Arena fields sometimes lists or JSON-encoded lists; return plain text.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return \"\\n\".join(s for s in x if isinstance(s, str)).strip()\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                arr = json.loads(s)\n",
    "                if isinstance(arr, list):\n",
    "                    return \"\\n\".join(str(t) for t in arr).strip()\n",
    "            except Exception:\n",
    "                pass\n",
    "        return s\n",
    "    return \"\" if x is None else str(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PRIMARY_CATS = [\"Code\", \"Math\", \"IF\", \"Creative Writing\", \"General\"]\n",
    "CRITERIA_KEYS = [\n",
    "    \"complexity\", \"creativity\", \"domain_knowledge\",\n",
    "    \"problem_solving\", \"real_world\", \"specificity\", \"technical_accuracy\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _infer_primary_category(row: dict) -> str:\n",
    "    \"\"\"Priority: Code > Math > IF > Creative Writing > General.\"\"\"\n",
    "    ct = row.get(\"category_tag\") or {}\n",
    "\n",
    "\n",
    "    def get_nested(d, *keys, default=False):\n",
    "        cur = d\n",
    "        for k in keys:\n",
    "            if not isinstance(cur, dict) or k not in cur:\n",
    "                return default\n",
    "            cur = cur[k]\n",
    "        return bool(cur)\n",
    "\n",
    "\n",
    "    if bool(row.get(\"is_code\", False)):\n",
    "        return \"Code\"\n",
    "    if get_nested(ct, \"math_v0.1\", \"math\"):\n",
    "        return \"Math\"\n",
    "    if get_nested(ct, \"if_v0.1\", \"if\"):\n",
    "        return \"IF\"\n",
    "    if get_nested(ct, \"creative_writing_v0.1\", \"creative_writing\"):\n",
    "        return \"Creative Writing\"\n",
    "    return \"General\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _extract_criteria(row: dict) -> Dict[str, bool]:\n",
    "    ct = row.get(\"category_tag\") or {}\n",
    "    out = {k: False for k in CRITERIA_KEYS}\n",
    "    criteria = ct.get(\"criteria_v0.1\", {}) if isinstance(ct, dict) else {}\n",
    "    for k in CRITERIA_KEYS:\n",
    "        v = criteria.get(k, False) if isinstance(criteria, dict) else False\n",
    "        out[k] = bool(v)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_prompt_from_full_conversation(fc) -> str:\n",
    "    \"\"\"\n",
    "    LM-Arena-140k style: take the *first* user turn text as the instruction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(fc, list) and len(fc) > 0:\n",
    "            first = fc[0]\n",
    "            u = first.get(\"user\", {}) if isinstance(first, dict) else {}\n",
    "            content = u.get(\"content\", [])\n",
    "            for item in content:\n",
    "                if isinstance(item, dict) and item.get(\"type\") == \"text\":\n",
    "                    t = item.get(\"text\", \"\")\n",
    "                    if t:\n",
    "                        return t.strip()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_model_text_from_turn(turn: dict, key: str) -> str:\n",
    "    \"\"\"Extract model text from 'model_side_a' or 'model_side_b' in a single turn.\"\"\"\n",
    "    side = turn.get(key, {}) if isinstance(turn, dict) else {}\n",
    "    content = side.get(\"content\", [])\n",
    "    for item in content:\n",
    "        if isinstance(item, dict) and item.get(\"type\") == \"text\":\n",
    "            t = item.get(\"text\", \"\")\n",
    "            if t:\n",
    "                return _as_text(t)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_two_responses_from_full_conversation(fc) -> Tuple[str, str]:\n",
    "    \"\"\"Take the *first* block's responses.\"\"\"\n",
    "    if not isinstance(fc, list) or len(fc) == 0:\n",
    "        return \"\", \"\"\n",
    "    first = fc[0]\n",
    "    a_text = _get_model_text_from_turn(first, \"model_side_a\")\n",
    "    b_text = _get_model_text_from_turn(first, \"model_side_b\")\n",
    "    return a_text, b_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _determine_winner(row: dict) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Return 'a', 'b', or None (tie/unknown).\n",
    "    Supports 'winner' str, boolean flags, and 'vote' dict.\n",
    "    \"\"\"\n",
    "    w = row.get(\"winner\", None)\n",
    "    if isinstance(w, str) and w:\n",
    "        ws = w.lower().strip()\n",
    "        if ws in {\"a\", \"model_a\", \"side_a\"}:\n",
    "            return \"a\"\n",
    "        if ws in {\"b\", \"model_b\", \"side_b\"}:\n",
    "            return \"b\"\n",
    "        if ws in {\"tie\", \"both\", \"both_bad\", \"equal\"}:\n",
    "            return None\n",
    "\n",
    "\n",
    "    for key in [\"winner_model_a\", \"winner_a\", \"is_model_a_winner\"]:\n",
    "        if bool(row.get(key, False)):\n",
    "            return \"a\"\n",
    "    for key in [\"winner_model_b\", \"winner_b\", \"is_model_b_winner\"]:\n",
    "        if bool(row.get(key, False)):\n",
    "            return \"b\"\n",
    "    if bool(row.get(\"winner_tie\", False)):\n",
    "        return None\n",
    "\n",
    "\n",
    "    vote = row.get(\"vote\", None)\n",
    "    if isinstance(vote, dict):\n",
    "        a_cnt = vote.get(\"a\") or vote.get(\"A\") or vote.get(\"model_a\") or 0\n",
    "        b_cnt = vote.get(\"b\") or vote.get(\"B\") or vote.get(\"model_b\") or 0\n",
    "        try:\n",
    "            a_cnt = int(a_cnt)\n",
    "            b_cnt = int(b_cnt)\n",
    "            if a_cnt > b_cnt:\n",
    "                return \"a\"\n",
    "            if b_cnt > a_cnt:\n",
    "                return \"b\"\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _format_prompt(text: str) -> str:\n",
    "    return f\"### Instruction:\\n{text.strip()}\\n\\n### Response:\\n\"\n",
    "\n",
    "\n",
    "\n",
    "def prep_sft_from_df(\n",
    "    df: pd.DataFrame,\n",
    "    seed: int = 25,\n",
    "    n_train: int = 2000,\n",
    "    n_eval: int = 100,\n",
    "    sample_per_category: Optional[int] = None,\n",
    "    require_language: str = \"en\",\n",
    "    dedupe: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Normalize LM-Arena-140k-style df into (prompt, completion) with stratified sampling by primary_category.\n",
    "    - Ties/unknown winners are dropped.\n",
    "    - Sampling balanced across primary_category (same as DPO code), using stable _row_id.\n",
    "    Returns: (train_df, train_ds, eval_ds, norm_df)\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "\n",
    "    # 1) Language filter\n",
    "    if require_language:\n",
    "        df_work = df[df[\"language\"] == require_language].copy()\n",
    "    else:\n",
    "        df_work = df.copy()\n",
    "\n",
    "\n",
    "    # 2) Normalize per-row into prompt/completion/primary_category/criteria\n",
    "    records = []\n",
    "    for _, row in df_work.iterrows():\n",
    "        fc = row.get(\"full_conversation\", None)\n",
    "        prompt_text = _get_prompt_from_full_conversation(fc)\n",
    "        a_text, b_text = _get_two_responses_from_full_conversation(fc)\n",
    "        winner = _determine_winner(row)\n",
    "\n",
    "\n",
    "        # usable prompt + both responses present\n",
    "        if not prompt_text or not a_text or not b_text:\n",
    "            continue\n",
    "\n",
    "\n",
    "        # pick chosen as completion\n",
    "        if winner == \"a\":\n",
    "            completion = a_text\n",
    "        elif winner == \"b\":\n",
    "            completion = b_text\n",
    "        else:\n",
    "            # tie/unknown -> drop\n",
    "            continue\n",
    "\n",
    "\n",
    "        if not completion.strip():\n",
    "            continue\n",
    "\n",
    "\n",
    "        prim_cat = _infer_primary_category(row)\n",
    "        criteria = _extract_criteria(row)\n",
    "\n",
    "\n",
    "        records.append({\n",
    "            \"prompt\": _format_prompt(_as_text(prompt_text)),\n",
    "            \"completion\": _as_text(completion),\n",
    "            \"primary_category\": prim_cat,\n",
    "            **{f\"crit_{k}\": v for k, v in criteria.items()}\n",
    "        })\n",
    "\n",
    "\n",
    "    norm_df = pd.DataFrame.from_records(records)\n",
    "    if norm_df.empty:\n",
    "        raise ValueError(\"No usable rows after normalization (SFT).\")\n",
    "\n",
    "\n",
    "    if dedupe:\n",
    "        before = len(norm_df)\n",
    "        norm_df = norm_df.drop_duplicates(subset=[\"prompt\", \"completion\"]).reset_index(drop=True)\n",
    "        after = len(norm_df)\n",
    "        print(f\"[sft] Deduped pairs: kept {after:,}/{before:,}\")\n",
    "\n",
    "\n",
    "    # Stable IDs for correct top-ups and disjoint eval\n",
    "    norm_df = norm_df.reset_index(drop=True)\n",
    "    norm_df[\"_row_id\"] = np.arange(len(norm_df), dtype=int)\n",
    "\n",
    "\n",
    "    # 3) Stratified sampling by primary_category (stable IDs)\n",
    "    cats_present = sorted(\n",
    "        norm_df[\"primary_category\"].unique().tolist(),\n",
    "        key=lambda x: PRIMARY_CATS.index(x) if x in PRIMARY_CATS else 999\n",
    "    )\n",
    "    if sample_per_category is None:\n",
    "        if n_train > 0 and len(cats_present) > 0:\n",
    "            sample_per_category = max(1, n_train // len(cats_present))\n",
    "        else:\n",
    "            sample_per_category = None\n",
    "\n",
    "\n",
    "    def stratified_ids(df_in: pd.DataFrame, total_n: int) -> list[int]:\n",
    "        selected: list[int] = []\n",
    "        # first pass: per-category quota\n",
    "        for cat in cats_present:\n",
    "            dcat = df_in[df_in[\"primary_category\"] == cat]\n",
    "            take = min(sample_per_category, len(dcat)) if sample_per_category is not None else len(dcat)\n",
    "            if take > 0:\n",
    "                ids = dcat.sample(n=take, random_state=seed)[\"_row_id\"].tolist()\n",
    "                selected.extend(ids)\n",
    "        # dedupe\n",
    "        selected = list(dict.fromkeys(selected))\n",
    "        # top-up\n",
    "        short = max(0, total_n - len(selected)) if total_n > 0 else 0\n",
    "        if short > 0:\n",
    "            remaining_ids = df_in.loc[~df_in[\"_row_id\"].isin(selected), \"_row_id\"]\n",
    "            if len(remaining_ids) > 0:\n",
    "                topup = remaining_ids.sample(n=min(short, len(remaining_ids)), random_state=seed).tolist()\n",
    "                selected.extend(topup)\n",
    "        # downsample if needed\n",
    "        if total_n > 0 and len(selected) > total_n:\n",
    "            selected = pd.Series(selected).sample(n=total_n, random_state=seed).tolist()\n",
    "        return selected\n",
    "\n",
    "\n",
    "    sel_ids = stratified_ids(norm_df, n_train if n_train > 0 else len(norm_df))\n",
    "    train_df = norm_df[norm_df[\"_row_id\"].isin(sel_ids)].copy()\n",
    "\n",
    "\n",
    "    eval_pool = norm_df[~norm_df[\"_row_id\"].isin(sel_ids)].copy()\n",
    "    if n_eval and len(eval_pool) > 0:\n",
    "        eval_ids = eval_pool[\"_row_id\"].sample(n=min(n_eval, len(eval_pool)), random_state=seed).tolist()\n",
    "        eval_df = eval_pool[eval_pool[\"_row_id\"].isin(eval_ids)].copy()\n",
    "    else:\n",
    "        eval_df = pd.DataFrame(columns=norm_df.columns)\n",
    "\n",
    "\n",
    "    if len(eval_df):\n",
    "        assert set(train_df[\"_row_id\"]).isdisjoint(set(eval_df[\"_row_id\"])), \"Train/Eval overlap!\"\n",
    "\n",
    "\n",
    "    # 4) Convert to HF Datasets (prompt, completion)\n",
    "    train_ds = HFDataset.from_pandas(train_df[[\"prompt\", \"completion\"]].reset_index(drop=True), preserve_index=False)\n",
    "    eval_ds = HFDataset.from_pandas(eval_df[[\"prompt\", \"completion\"]].reset_index(drop=True), preserve_index=False) if len(eval_df) else None\n",
    "\n",
    "\n",
    "    return train_df, train_ds, eval_ds, norm_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_examples_sft(ds: HFDataset, k: int = 2, title: str = \"SFT samples\") -> None:\n",
    "    if ds is None or len(ds) == 0 or k <= 0:\n",
    "        return\n",
    "    print(f\"\\n{title}:\")\n",
    "    idx = list(range(len(ds)))\n",
    "    rng = np.random.default_rng(13)\n",
    "    rng.shuffle(idx)\n",
    "    idx = idx[: min(k, len(idx))]\n",
    "    for i in idx:\n",
    "        ex = ds[i]\n",
    "        print(\"=\"*80)\n",
    "        print(ex[\"prompt\"])\n",
    "        print(\"--- completion (first 300) ---\")\n",
    "        print(ex[\"completion\"][:300])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_sft_parquet(\n",
    "    train_df: pd.DataFrame,\n",
    "    eval_df: pd.DataFrame,\n",
    "    norm_df: pd.DataFrame,\n",
    "    outdir: str = \"prepared_sft_dataset\",\n",
    "    lang_tag: str = \"en\",\n",
    "    n_train: int = 0,\n",
    "    n_eval: int = 0,\n",
    "    seed: int = 25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save normalized pool and splits. Splits contain only (prompt, completion).\n",
    "    \"\"\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "\n",
    "    norm_path = os.path.join(outdir, f\"arena140k_sft_normalized_lang-{lang_tag}.parquet\")\n",
    "    train_path = os.path.join(outdir, f\"train_sft_{lang_tag}_n{n_train or len(train_df)}.parquet\")\n",
    "    eval_path  = os.path.join(outdir, f\"eval_sft_{lang_tag}_n{n_eval or len(eval_df)}.parquet\")\n",
    "\n",
    "\n",
    "    # Save normalized (keep audit cols)\n",
    "    norm_df.to_parquet(norm_path, index=False)\n",
    "\n",
    "\n",
    "    # Save splits (only prompt/completion)\n",
    "    train_df[[\"prompt\", \"completion\"]].to_parquet(train_path, index=False)\n",
    "    if len(eval_df):\n",
    "        eval_df[[\"prompt\", \"completion\"]].to_parquet(eval_path, index=False)\n",
    "\n",
    "\n",
    "    meta = {\n",
    "        \"language\": lang_tag,\n",
    "        \"n_train\": int(n_train or len(train_df)),\n",
    "        \"n_eval\": int(n_eval or len(eval_df)),\n",
    "        \"seed\": seed,\n",
    "        \"columns\": {\"splits\": [\"prompt\", \"completion\"], \"normalized_extra\": [\"primary_category\"] + [f\"crit_{k}\" for k in CRITERIA_KEYS]},\n",
    "    }\n",
    "    with open(os.path.join(outdir, \"meta_sft.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "\n",
    "    print(\"[sft] Wrote:\")\n",
    "    print(\" -\", norm_path)\n",
    "    print(\" -\", train_path)\n",
    "    if len(eval_df):\n",
    "        print(\" -\", eval_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40c9838-8b4d-41f0-a790-dc1fa7c540b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sft] Deduped pairs: kept 48,148/51,616\n",
      "\n",
      "Train SFT Samples:\n",
      "================================================================================\n",
      "### Instruction:\n",
      "create an svg of a left handed baseball player for the texas rangers on an october night, close to halloween\n",
      "\n",
      "### Response:\n",
      "\n",
      "--- completion (first 300) ---\n",
      "Below is a compact, self-contained SVG that depicts a *left-handed* Texas Rangers batter on a crisp late-October night—complete with a full moon, twinkling stars, and a cheeky little pumpkin to hint at Halloween.  \n",
      "Just copy everything between the triple back-ticks into an `.svg` file and open it in\n",
      "================================================================================\n",
      "### Instruction:\n",
      "Tell me a joke that has multiple layers of meaning, as much as you can\n",
      "\n",
      "### Response:\n",
      "\n",
      "--- completion (first 300) ---\n",
      "Here’s a multi-layered joke for you:  \n",
      "\n",
      "**\"A man walks into a library and asks the librarian for books on paranoia. The librarian whispers, 'They’re right behind you...'\"**  \n",
      "\n",
      "### **Layers of Meaning:**  \n",
      "1. **Surface-Level Humor:** It’s a classic misdirection joke—the librarian’s whisper implies th\n",
      "\n",
      "Eval SFT Samples:\n",
      "================================================================================\n",
      "### Instruction:\n",
      "Make a draft of a resume of a senior react developer seeking for a job in lithuania in 2025 with current stagnating market\n",
      "\n",
      "### Response:\n",
      "\n",
      "--- completion (first 300) ---\n",
      "Certainly! Below is a well-structured, competitive resume draft for a **Senior React Developer** seeking opportunities in Lithuania in 2025, considering the current market stagnation. The resume emphasizes **technical expertise, leadership, and adaptability** to stand out in a challenging job market\n",
      "[sft] Wrote:\n",
      " - prepared_sft_dataset/arena140k_sft_normalized_lang-en.parquet\n",
      " - prepared_sft_dataset/train_sft_en_n12000.parquet\n",
      " - prepared_sft_dataset/eval_sft_en_n512.parquet\n"
     ]
    }
   ],
   "source": [
    "train_df_sft, train_ds_sft, eval_ds_sft, norm_df_sft = prep_sft_from_df(\n",
    "    df2,\n",
    "    seed=25,            # keep same seed as DPO\n",
    "    n_train=12000,      # match your DPO train size\n",
    "    n_eval=512,         # match your DPO eval size\n",
    "    require_language=\"en\"\n",
    ")\n",
    "\n",
    "\n",
    "show_examples_sft(train_ds_sft, k=2, title=\"Train SFT Samples\")\n",
    "show_examples_sft(eval_ds_sft,  k=1, title=\"Eval SFT Samples\")\n",
    "\n",
    "\n",
    "# Save Parquet splits you can train from\n",
    "save_sft_parquet(\n",
    "    train_df=train_df_sft,\n",
    "    eval_df=pd.DataFrame(eval_ds_sft) if eval_ds_sft is not None else pd.DataFrame(columns=train_df_sft.columns),\n",
    "    norm_df=norm_df_sft,\n",
    "    outdir=\"prepared_sft_dataset\",\n",
    "    lang_tag=\"en\",\n",
    "    n_train=12000,\n",
    "    n_eval=512,\n",
    "    seed=25,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1fe958-cfa6-4af1-ac39-89cf929743ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>crit_complexity</th>\n",
       "      <th>crit_creativity</th>\n",
       "      <th>crit_domain_knowledge</th>\n",
       "      <th>crit_problem_solving</th>\n",
       "      <th>crit_real_world</th>\n",
       "      <th>crit_specificity</th>\n",
       "      <th>crit_technical_accuracy</th>\n",
       "      <th>_row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### Instruction:\\nDo you need to be folkbord(r...</td>\n",
       "      <td>For Swedish citizenship, you generally need to...</td>\n",
       "      <td>General</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### Instruction:\\nWhat are Tricky the Clown's ...</td>\n",
       "      <td>Tricky the Clown is a character from the *Madn...</td>\n",
       "      <td>General</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>### Instruction:\\ndf with cols\\n'perf', 'n_tri...</td>\n",
       "      <td>I'll help you create a scatter plot comparing ...</td>\n",
       "      <td>Code</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>### Instruction:\\ncreate ifc file with a wall ...</td>\n",
       "      <td>Creating an **IFC (Industry Foundation Classes...</td>\n",
       "      <td>Code</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>### Instruction:\\ni store the data of store th...</td>\n",
       "      <td>Okay, this is a common challenge, and the \"mat...</td>\n",
       "      <td>Code</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48138</th>\n",
       "      <td>### Instruction:\\nWhat are 20 examples of high...</td>\n",
       "      <td>I can't provide guidance on greyhat methods fo...</td>\n",
       "      <td>Code</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>48138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48139</th>\n",
       "      <td>### Instruction:\\nHow would you improve LLMs w...</td>\n",
       "      <td>Okay, let's break down how Reinforcement Learn...</td>\n",
       "      <td>IF</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>48139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48143</th>\n",
       "      <td>### Instruction:\\nhttps://github.com/NousResea...</td>\n",
       "      <td>Okay, let's break down how you might approach ...</td>\n",
       "      <td>Code</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>48143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48145</th>\n",
       "      <td>### Instruction:\\nwrite a funny fictional answ...</td>\n",
       "      <td>Behold! The **Official 7-Step Guide to Feline ...</td>\n",
       "      <td>Creative Writing</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>48145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48146</th>\n",
       "      <td>### Instruction:\\nThe light on my Dyson Zone i...</td>\n",
       "      <td>Since this appears to be a stuck firmware upda...</td>\n",
       "      <td>General</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>48146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "1      ### Instruction:\\nDo you need to be folkbord(r...   \n",
       "2      ### Instruction:\\nWhat are Tricky the Clown's ...   \n",
       "8      ### Instruction:\\ndf with cols\\n'perf', 'n_tri...   \n",
       "17     ### Instruction:\\ncreate ifc file with a wall ...   \n",
       "18     ### Instruction:\\ni store the data of store th...   \n",
       "...                                                  ...   \n",
       "48138  ### Instruction:\\nWhat are 20 examples of high...   \n",
       "48139  ### Instruction:\\nHow would you improve LLMs w...   \n",
       "48143  ### Instruction:\\nhttps://github.com/NousResea...   \n",
       "48145  ### Instruction:\\nwrite a funny fictional answ...   \n",
       "48146  ### Instruction:\\nThe light on my Dyson Zone i...   \n",
       "\n",
       "                                              completion  primary_category  \\\n",
       "1      For Swedish citizenship, you generally need to...           General   \n",
       "2      Tricky the Clown is a character from the *Madn...           General   \n",
       "8      I'll help you create a scatter plot comparing ...              Code   \n",
       "17     Creating an **IFC (Industry Foundation Classes...              Code   \n",
       "18     Okay, this is a common challenge, and the \"mat...              Code   \n",
       "...                                                  ...               ...   \n",
       "48138  I can't provide guidance on greyhat methods fo...              Code   \n",
       "48139  Okay, let's break down how Reinforcement Learn...                IF   \n",
       "48143  Okay, let's break down how you might approach ...              Code   \n",
       "48145  Behold! The **Official 7-Step Guide to Feline ...  Creative Writing   \n",
       "48146  Since this appears to be a stuck firmware upda...           General   \n",
       "\n",
       "       crit_complexity  crit_creativity  crit_domain_knowledge  \\\n",
       "1                False            False                   True   \n",
       "2                False            False                   True   \n",
       "8                 True            False                   True   \n",
       "17                True            False                   True   \n",
       "18                True             True                   True   \n",
       "...                ...              ...                    ...   \n",
       "48138             True             True                   True   \n",
       "48139             True             True                   True   \n",
       "48143             True             True                   True   \n",
       "48145             True             True                  False   \n",
       "48146             True             True                   True   \n",
       "\n",
       "       crit_problem_solving  crit_real_world  crit_specificity  \\\n",
       "1                      True             True             False   \n",
       "2                     False            False             False   \n",
       "8                      True             True              True   \n",
       "17                     True             True              True   \n",
       "18                     True             True              True   \n",
       "...                     ...              ...               ...   \n",
       "48138                  True             True              True   \n",
       "48139                  True             True              True   \n",
       "48143                  True             True              True   \n",
       "48145                 False            False             False   \n",
       "48146                  True             True              True   \n",
       "\n",
       "       crit_technical_accuracy  _row_id  \n",
       "1                        False        1  \n",
       "2                        False        2  \n",
       "8                         True        8  \n",
       "17                        True       17  \n",
       "18                        True       18  \n",
       "...                        ...      ...  \n",
       "48138                     True    48138  \n",
       "48139                     True    48139  \n",
       "48143                     True    48143  \n",
       "48145                    False    48145  \n",
       "48146                     True    48146  \n",
       "\n",
       "[12000 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b0f8d6-2ad3-4529-bc0f-a9de27a60e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep  1 23:48:35 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |\n",
      "|  0%   33C    P0             62W /  300W |   15071MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |\n",
      "|  0%   34C    P0             63W /  300W |   16855MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |\n",
      "|  0%   34C    P0             62W /  300W |   16855MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   34C    P0             64W /  300W |   10693MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           42061      C   .../envs/pytorch_p310/bin/python      15062MiB |\n",
      "|    1   N/A  N/A           42061      C   .../envs/pytorch_p310/bin/python      16846MiB |\n",
      "|    2   N/A  N/A           42061      C   .../envs/pytorch_p310/bin/python      16846MiB |\n",
      "|    3   N/A  N/A           42061      C   .../envs/pytorch_p310/bin/python      10684MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c8639-54a4-4146-8b80-fbb5f60796ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
